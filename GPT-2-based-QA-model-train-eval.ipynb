{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2-based-QA-model-train-eval",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPd_GMWqXVfi"
      },
      "source": [
        "The GPT-2 based system implementation is based on by [gpt-2-simple package by Max Woolf](https://minimaxir.com/2019/09/howto-gpt2/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBmKb_EbQqw"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from collections import counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vum76-AVbrlw"
      },
      "source": [
        "## Initializing the model\n",
        "\n",
        "GPT-2 with 774 million parameter was used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"774M\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3IElYUbc1Fo"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2NjHIRIdFR6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWWmLyVvdGDN"
      },
      "source": [
        "Later it will possible to save GPT-2 weights in the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLcaXTCbdUGY"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4fCKbOocCB7"
      },
      "source": [
        "## Model fine-tuning\n",
        "\n",
        "Defining the file with the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"train.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp11XBp_cQG4"
      },
      "source": [
        "Setting the fine-tuning parameters and starting the training session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name, # path to the the training data\n",
        "              model_name='774M', # GPT-2 with 774 million parameters was chosen\n",
        "              steps=3000, # number of training steps\n",
        "              restore_from='fresh', \n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtG4uMWEdipU"
      },
      "source": [
        "Saving the weight to the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='checkpoint_run1.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqX-V08KVS1Q"
      },
      "source": [
        "## Model initialization\r\n",
        "\r\n",
        "Getting the model weights from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFjZq3DOW98F"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBywHJu4W_cm"
      },
      "source": [
        "Starting the session and loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9fRbEJoXBq5"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\r\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ozF81TXDL9"
      },
      "source": [
        "## Obtaining the results\r\n",
        "\r\n",
        "Splitting the validation set into question and answers sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jqUnB_bXFwk"
      },
      "source": [
        "val_questions = []\r\n",
        "q = -2\r\n",
        "for i in range(len(val)):\r\n",
        "  q += 2\r\n",
        "  if i + q < len(val):\r\n",
        "    val_questions.append(val[i + q])\r\n",
        "\r\n",
        "val_answers = []\r\n",
        "a = -1\r\n",
        "for i in range(len(val)):\r\n",
        "  a += 2\r\n",
        "  if i + a < len(val):\r\n",
        "    val_answers.append(val[i + a])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K68GnL-OXIpp"
      },
      "source": [
        "Generating the answers to questions from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I56rcvboXG-W"
      },
      "source": [
        "eval_answers = []\r\n",
        "for question in val_questions:\r\n",
        "  answer = gpt2.generate(sess,\r\n",
        "                length=300,\r\n",
        "                temperature=0.7,\r\n",
        "                top_k=40,\r\n",
        "                prefix=question,\r\n",
        "                nsamples=1,\r\n",
        "                batch_size=5,\r\n",
        "                )\r\n",
        "  eval_answers.append(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlhPn6o7XLOI"
      },
      "source": [
        "Computing Precision, Recal, F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v7qu1RXXNtj"
      },
      "source": [
        "num_c = []\r\n",
        "num_p = []\r\n",
        "num_g = []\r\n",
        "\r\n",
        "for a in range(len(eval_answers)):\r\n",
        "\r\n",
        "  common = collections.Counter(val_answers[a].split()) & collections.Counter(eval_answers[a].split()) # tokens shared between gold and predicted answers\r\n",
        "  num_common = sum(common.values())\r\n",
        "\r\n",
        "  num_pred = len(str(eval_answers[a]).split()) # the number of predicted tokens\r\n",
        "\r\n",
        "  num_gold = len(str(val_answers[a]).split()) # the number of gold tokens\r\n",
        "\r\n",
        "  num_c.append(num_common)\r\n",
        "  num_p.append(num_pred)\r\n",
        "  num_g.append(num_gold)\r\n",
        "\r\n",
        "precision = 1.0 * sum(num_c) / sum(num_p) # the num of tokens shared between gold and predicted answers / the num of predicted tokens\r\n",
        "recall = 1.0 * sum(num_c) / sum(num_g) # the num of tokens shared between gold and predicted answers / the num of gold tokens\r\n",
        "f1_score = (2 * precision * recall) / (precision + recall)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}